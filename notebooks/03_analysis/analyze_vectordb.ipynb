{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13addae4-cb04-4494-9955-5ca2ec45cd65",
   "metadata": {},
   "source": [
    "# Analyze Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbaa76c-33ca-4e47-95a1-099e2b9ea339",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa98434-1313-4b11-91ec-0ce941be6901",
   "metadata": {},
   "source": [
    "## Specify the embedding model and vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nrbw9ze234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== CONFIGURATION ==========\n",
    "# Change this to analyze different databases\n",
    "DATABASE_OPTIONS = {\n",
    "    \"qa\": \"../../data/vectordbs/qa_tool/\",\n",
    "    \"code_gen\": \"../../data/vectordbs/code_gen/\",\n",
    "    \"custom\": \"my_vector_store\"  # For ad-hoc testing\n",
    "}\n",
    "\n",
    "ANALYZE_DB = \"qa\"  # <<< Change this to switch databases\n",
    "# ===================================\n",
    "\n",
    "database_loc = DATABASE_OPTIONS[ANALYZE_DB]\n",
    "print(f\"Analyzing database: {ANALYZE_DB}\")\n",
    "print(f\"Path: {database_loc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae17a76d-4284-4dc4-bf2f-2914f622055f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-mpnet-base-v2\")\n",
    "\n",
    "vectorstore = Chroma(persist_directory=database_loc,\n",
    "      embedding_function=embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ea5fad-15d3-42f2-9c8a-6813e58a1ae2",
   "metadata": {},
   "source": [
    "### (optional) Print the contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3046f1f2-683c-4274-84e8-4a5772df937e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = vectorstore.get()['documents']\n",
    "\n",
    "print(f\"docs: {len(all_docs)}\")\n",
    "\n",
    "# for idx, doc in enumerate(all_docs):\n",
    "#     print(f\"Document {idx + 1}:\")\n",
    "#     print(doc)\n",
    "#     print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc32f82-5c4e-40eb-a8fe-ebfe58f7a3fc",
   "metadata": {},
   "source": [
    "## Run a similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bedd55-a8c6-4dac-a1d5-c3d4e65b9300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain_core.runnables import chain\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "@chain\n",
    "def retriever(query: str) -> List[Document]:\n",
    "    docs, scores = zip(*vectorstore.similarity_search_with_score(query, k=8))\n",
    "    for doc, score in zip(docs, scores):\n",
    "        doc.metadata[\"score\"] = score\n",
    "\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2196ea26-3310-4f96-86ab-4aaada22b212",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = \"What are slices?\"\n",
    "embedding = HuggingFaceEmbeddings().embed_query(phrase)\n",
    "\n",
    "results = retriever.invoke(phrase)\n",
    "#print(results)\n",
    "\n",
    "for result in results:\n",
    "    print(result.metadata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fabric-ai-tool-deployment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
