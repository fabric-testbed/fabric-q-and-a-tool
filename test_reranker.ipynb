{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13addae4-cb04-4494-9955-5ca2ec45cd65",
   "metadata": {},
   "source": [
    "# Analyze Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbaa76c-33ca-4e47-95a1-099e2b9ea339",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa98434-1313-4b11-91ec-0ce941be6901",
   "metadata": {},
   "source": [
    "## Specify the embedding model and vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae17a76d-4284-4dc4-bf2f-2914f622055f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-mpnet-base-v2\")\n",
    "database_loc = \"/path/to/vectorDB\"\n",
    "vectorstore = Chroma(persist_directory=database_loc,\n",
    "      embedding_function=embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ea5fad-15d3-42f2-9c8a-6813e58a1ae2",
   "metadata": {},
   "source": [
    "### (optional) Print the contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3046f1f2-683c-4274-84e8-4a5772df937e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = vectorstore.get()['documents']\n",
    "\n",
    "print(f\"docs: {len(all_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f31dd4b-3c56-4b41-94c9-9971a9349e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vectorstore.get().keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc32f82-5c4e-40eb-a8fe-ebfe58f7a3fc",
   "metadata": {},
   "source": [
    "## Test Re-ranker and compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bedd55-a8c6-4dac-a1d5-c3d4e65b9300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain_core.runnables import chain\n",
    "from langchain_core.documents import Document\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "@chain\n",
    "def retriever(query: str) -> List[Document]:\n",
    "    docs, scores = zip(*vectorstore.similarity_search_with_score(query, k=200))\n",
    "    for doc, score in zip(docs, scores):\n",
    "        doc.metadata[\"original_score\"] = score\n",
    "\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2196ea26-3310-4f96-86ab-4aaada22b212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 2. Get top-k documents ===\n",
    "phrase = \"Why do I need both sliver and bastion keys?\"\n",
    "results = retriever.invoke(phrase)\n",
    "\n",
    "docs = [{\n",
    "    \"id\": str(i),\n",
    "    \"text\": x.page_content,\n",
    "    \"metadata\": x.metadata\n",
    "} for i, x in enumerate(results)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac8280c-4a4c-428a-b1d2-11c838f1687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 3. Load reranker model ===\n",
    "\n",
    "# Detect device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-reranker-v2-m3\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"BAAI/bge-reranker-v2-m3\").to(device)\n",
    "print(f\"Using device: {device}\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a4de2d-8987-4440-b713-53f8a6878131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 4. Prepare inputs for reranking ===\n",
    "pairs = [(phrase, doc[\"text\"]) for doc in docs]\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    inputs = tokenizer.batch_encode_plus(\n",
    "        pairs,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=512\n",
    "    )\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    outputs = model(**inputs)\n",
    "    scores = outputs.logits.squeeze().tolist()\n",
    "\n",
    "# Add reranked scores to docs\n",
    "for doc, score in zip(docs, scores):\n",
    "    doc[\"metadata\"][\"rerank_score\"] = score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930bcae8-58e3-482f-b2b4-8fe43133e857",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 5. Print and compare rankings ===\n",
    "print(\"\\n=== Original Ranking ===\")\n",
    "for doc in docs:\n",
    "    print(f\"Doc ID: {doc['id']}, Original Score: {doc['metadata']['original_score']:.4f}, URL: {doc['metadata']['source']}\")\n",
    "\n",
    "print(\"\\n=== Reranked by BAAI/bge-reranker-v2-m3 ===\")\n",
    "for doc in sorted(docs, key=lambda x: x[\"metadata\"][\"rerank_score\"], reverse=True):\n",
    "    print(f\"Doc ID: {doc['id']}, Rerank Score: {doc['metadata']['rerank_score']:.4f}, URL: {doc['metadata']['source']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d1d59e-3a36-4ce6-9a80-a98cce886a9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224d32fa-d9ed-418e-882b-b72f30d682e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
